{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Sequence, Tuple, Dict\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few examples of State Value function in the gridworld settings explained in [Chapter 3](http://incompleteideas.net/book/RLbook2018.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gridworld"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Gridworld environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridWorldEnv:\n",
    "    \"\"\"Manage Gridworld environment\"\"\"\n",
    "    def __init__(self, special_rewards: Dict, special_moves: Dict, dim: int = 5, ):\n",
    "        \"\"\"\n",
    "        Create gridworld\n",
    "        :param special_rewards: special reward when moving from this place, dict((row, col), reward)\n",
    "        :param special_rewards: special moves when moving from this place, dict((row, col), (dest_row, dest_col))\n",
    "        :param dim: grid lateral dimension\n",
    "        \"\"\"\n",
    "        assert len(special_moves) == len(special_rewards)\n",
    "        assert all(x in special_rewards for x in special_moves)\n",
    "        \n",
    "        self.special_reward = special_rewards\n",
    "        self.special_moves = special_moves\n",
    "        self.dim = dim\n",
    "        self.possible_actions = {\n",
    "            'up': (-1, 0),\n",
    "            'down': (1, 0),\n",
    "            'left': (0, -1),\n",
    "            'right': (0, 1)\n",
    "        }\n",
    "        \n",
    "    def show_full_space(self):\n",
    "        \"\"\"Show all possible action/state combinations and their rewards\"\"\"\n",
    "        for i in range(self.dim):\n",
    "            for k in range(self.dim):\n",
    "                for action_name, action in self.possible_actions.items():\n",
    "                    reward, next_pos = self.step(current_position=(i, k), action_name=action_name)\n",
    "                    print(f\"from {(i, k)} move {action_name} --> into {next_pos} with R={reward}\")\n",
    "                    \n",
    "    def step(self, current_position: Tuple[int, int], action_name: str):\n",
    "        \"\"\"Get reward and next position/state\"\"\"\n",
    "        assert action_name in self.possible_actions, f\"Action {action_name} not among possible actions\"\n",
    "        \n",
    "        action_x, action_y = self.possible_actions[action_name]\n",
    "        i, k = current_position\n",
    "        next_pos = i+action_x, k+action_y\n",
    "        if (i, k) in self.special_moves:  # special move get fixed reward and always move to one location\n",
    "            next_pos = self.special_moves[(i, k)]\n",
    "            reward = self.special_reward[(i, k)]\n",
    "        elif next_pos[0] < 0 or next_pos[0] > self.dim-1 or next_pos[1] < 0 or next_pos[1] > self.dim-1:\n",
    "            next_pos = i, k\n",
    "            reward = -1\n",
    "        else:\n",
    "            reward = 0\n",
    "        \n",
    "        return reward, next_pos\n",
    "    \n",
    "    def grid_to_vec(self, row: int, col: int) -> int:\n",
    "        \"\"\"get index of vector which corresponds to a grid position\"\"\"\n",
    "        assert 0 <= row < self.dim, f\"Invalid row number {row}, max is {self.dim - 1}\"\n",
    "        assert 0 <= col < self.dim, f\"Invalid column number {col}, max is {self.dim - 1}\"\n",
    "        \n",
    "        return row * self.dim + col\n",
    "\n",
    "    def vec_to_grid(self, idx: int) -> Tuple[int, int]:\n",
    "        \"\"\"get grid position which corresponds to index of vector\"\"\"\n",
    "        assert 0 <= idx < self.dim * self.dim, f\"Invalid index {idx}, max is {self.dim * self.dim - 1}\"\n",
    "        \n",
    "        return idx // self.dim, idx % self.dim\n",
    "    \n",
    "    def dict_to_grid(self, fun_on_grid: dict):\n",
    "        ans = []\n",
    "        for row in range(self.dim):\n",
    "            ans.append({f\"col_{col}\": fun_on_grid[(row, col)] for col in range(self.dim)})\n",
    "\n",
    "        return pd.DataFrame(ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use GridWorld with a small grid and display full spectrum of states-actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from (0, 0) move up --> into (0, 0) with R=-1\n",
      "from (0, 0) move down --> into (1, 0) with R=0\n",
      "from (0, 0) move left --> into (0, 0) with R=-1\n",
      "from (0, 0) move right --> into (0, 1) with R=0\n",
      "from (0, 1) move up --> into (0, 1) with R=-1\n",
      "from (0, 1) move down --> into (1, 1) with R=0\n",
      "from (0, 1) move left --> into (0, 0) with R=0\n",
      "from (0, 1) move right --> into (0, 1) with R=-1\n",
      "from (1, 0) move up --> into (0, 0) with R=0\n",
      "from (1, 0) move down --> into (1, 0) with R=-1\n",
      "from (1, 0) move left --> into (1, 0) with R=-1\n",
      "from (1, 0) move right --> into (1, 1) with R=0\n",
      "from (1, 1) move up --> into (0, 0) with R=10\n",
      "from (1, 1) move down --> into (0, 0) with R=10\n",
      "from (1, 1) move left --> into (0, 0) with R=10\n",
      "from (1, 1) move right --> into (0, 0) with R=10\n"
     ]
    }
   ],
   "source": [
    "env = GridWorldEnv(special_rewards={(1, 1): 10}, special_moves={(1, 1): (0, 0)}, dim=2)\n",
    "env.show_full_space()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define solver for the Bellman equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BellmanSolver:\n",
    "    \"\"\"Bellman equation solver\"\"\"\n",
    "    def __init__(self, env: GridWorldEnv, gamma: float):\n",
    "        \"\"\"\n",
    "        Initialize solver\n",
    "        :param env: gridworld environment\n",
    "        :param: gamma: discount factor\n",
    "        \"\"\"\n",
    "        self.gamma = gamma\n",
    "        self.env = env\n",
    "    \n",
    "    def bellman_eq_random_policy(self):\n",
    "        \"\"\"Solve bellman uquation under random policy, this is a linear system of equations\"\"\"\n",
    "        size = self.env.dim ** 2  # linear system size\n",
    "        coeff = 1/4  # probability under random policy\n",
    "        matrix = np.zeros([size, size])\n",
    "        known_term = np.zeros(size)\n",
    "\n",
    "        # build matrix\n",
    "        for idx in range(size):  # loop on equations\n",
    "            current_position = self.env.vec_to_grid(idx)\n",
    "            matrix[idx, idx] = 1\n",
    "\n",
    "            for action in self.env.possible_actions:  # loop on four possible actions\n",
    "                reward, next_position = self.env.step(current_position=current_position, action_name=action)\n",
    "                known_term[idx] += coeff * reward\n",
    "                idx_other = self.env.grid_to_vec(*next_position)\n",
    "                matrix[idx, idx_other] -= coeff * self.gamma\n",
    "\n",
    "        # solve linear system and push results to grid\n",
    "        return np.linalg.solve(matrix, known_term)\n",
    "    \n",
    "    def bellman_optimal(self, v: np.array) -> np.array:\n",
    "        \"\"\"\n",
    "        Nonlinear Bellman equation for the optimal value function\n",
    "        :param v: current value function\n",
    "        :return: L2 norm of current value of the residuals of the equation \n",
    "        \"\"\"\n",
    "        f = np.zeros(v.shape)\n",
    "        for idx in range(f.size):\n",
    "            current_position = self.env.vec_to_grid(idx)\n",
    "\n",
    "            max_over_a = -np.Inf\n",
    "            for action in self.env.possible_actions:  # loop on four possible actions\n",
    "                reward, next_position = self.env.step(current_position=current_position, action_name=action)\n",
    "                idx_next = self.env.grid_to_vec(*next_position)\n",
    "                max_over_a = max(max_over_a, reward + self.gamma * v[idx_next])\n",
    "\n",
    "            f[idx] = max_over_a - v[idx]\n",
    "\n",
    "        return np.linalg.norm(f)\n",
    "    \n",
    "    def find_optimal_policy(self, optimal_val_fun: np.array) -> np.array:\n",
    "        \"\"\"\n",
    "        Given an optimal value function, find the optimal policy\n",
    "        :param optimal_val_fun: optimal value function\n",
    "        :return: optimal policy\n",
    "        \"\"\"\n",
    "        ans = {}\n",
    "        for idx_pos in range(optimal_val_fun.size):\n",
    "            pos = self.env.vec_to_grid(idx_pos)\n",
    "\n",
    "            values, actions = [], []\n",
    "            for action in self.env.possible_actions:\n",
    "                r, next_pos = self.env.step(action_name=action, current_position=pos)\n",
    "                idx = self.env.grid_to_vec(*next_pos)\n",
    "                values.append(r + self.gamma * optimal_val_fun[idx])\n",
    "                actions.append(action)\n",
    "            values = np.array([np.around(x, 3) for x in values])\n",
    "\n",
    "            ans[pos] = [actions[i] for i in np.where(values == values.max())[0]]\n",
    "\n",
    "        return ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Value function under random policy\n",
    "For a given policy (e.g. random policy) the Belmlman equation leads to the value function by solving a system of linear equations.\n",
    "\n",
    "The cell below gives the value function for each state, under optimal policy.\n",
    "Result should be the same as in [figure 3.2](http://incompleteideas.net/book/RLbook2018.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col_0</th>\n",
       "      <th>col_1</th>\n",
       "      <th>col_2</th>\n",
       "      <th>col_3</th>\n",
       "      <th>col_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.3</td>\n",
       "      <td>8.8</td>\n",
       "      <td>4.4</td>\n",
       "      <td>5.3</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>-1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.9</td>\n",
       "      <td>-1.3</td>\n",
       "      <td>-1.2</td>\n",
       "      <td>-1.4</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   col_0  col_1  col_2  col_3  col_4\n",
       "0    3.3    8.8    4.4    5.3    1.5\n",
       "1    1.5    3.0    2.3    1.9    0.5\n",
       "2    0.1    0.7    0.7    0.4   -0.4\n",
       "3   -1.0   -0.4   -0.4   -0.6   -1.2\n",
       "4   -1.9   -1.3   -1.2   -1.4   -2.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialze environment\n",
    "env = GridWorldEnv(special_rewards={(0, 1): 10, (0, 3): 5}, special_moves={(0, 1): (4, 1), (0, 3): (2, 3)})\n",
    "\n",
    "# initialze solver\n",
    "solver = BellmanSolver(env=env, gamma=.9)\n",
    "\n",
    "# solve Bellman equation under random policy\n",
    "res = solver.bellman_eq_random_policy()\n",
    "\n",
    "# plot result on grid\n",
    "env.dict_to_grid(fun_on_grid={env.vec_to_grid(x): np.around(res[x], 1) for x in range(res.size)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimal value function\n",
    "The optimal value function can be found by solving the Belmann optimality equation (eq. 3.19). The Bellman optimaly equation is nonlinear in $v(s)$. Here we solve it numerically as a minimization problem: find the minimum of the L2 norm of the residuals (the equation is verified when the norm goes to zero)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Objective function value: 8.44544193687595e-06\n"
     ]
    }
   ],
   "source": [
    "res_optim = minimize(solver.bellman_optimal, res, method='SLSQP', options={'maxiter': 1e4})\n",
    "assert res_optim['success'], f'Optimization unsucessfull! {res_optim[\"message\"]}'\n",
    "print(f\"Objective function value: {res_optim['fun']}\")\n",
    "optimal_val_fun = res_optim['x']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result, shown below, should be the same as in figure 3.5-B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col_0</th>\n",
       "      <th>col_1</th>\n",
       "      <th>col_2</th>\n",
       "      <th>col_3</th>\n",
       "      <th>col_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>24.4</td>\n",
       "      <td>22.0</td>\n",
       "      <td>19.4</td>\n",
       "      <td>17.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19.8</td>\n",
       "      <td>22.0</td>\n",
       "      <td>19.8</td>\n",
       "      <td>17.8</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.8</td>\n",
       "      <td>19.8</td>\n",
       "      <td>17.8</td>\n",
       "      <td>16.0</td>\n",
       "      <td>14.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>16.0</td>\n",
       "      <td>14.4</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14.4</td>\n",
       "      <td>16.0</td>\n",
       "      <td>14.4</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   col_0  col_1  col_2  col_3  col_4\n",
       "0   22.0   24.4   22.0   19.4   17.5\n",
       "1   19.8   22.0   19.8   17.8   16.0\n",
       "2   17.8   19.8   17.8   16.0   14.4\n",
       "3   16.0   17.8   16.0   14.4   13.0\n",
       "4   14.4   16.0   14.4   13.0   11.7"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# plot result on grid\n",
    "env.dict_to_grid(fun_on_grid={env.vec_to_grid(x): np.around(optimal_val_fun[x], 1)\n",
    "                              for x in range(optimal_val_fun.size)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimal policy\n",
    "Once the value function is known, the optimal policy is found as the policy that maximize the one step action \"any policy that is greedy with respect to the optimal evaluation function vâ‡¤ is an optimal policy\". This results should be the same as figure 3.5-C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col_0</th>\n",
       "      <th>col_1</th>\n",
       "      <th>col_2</th>\n",
       "      <th>col_3</th>\n",
       "      <th>col_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[right]</td>\n",
       "      <td>[up, down, left, right]</td>\n",
       "      <td>[left]</td>\n",
       "      <td>[up, down, left, right]</td>\n",
       "      <td>[left]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[up, right]</td>\n",
       "      <td>[up]</td>\n",
       "      <td>[up, left]</td>\n",
       "      <td>[left]</td>\n",
       "      <td>[left]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[up, right]</td>\n",
       "      <td>[up]</td>\n",
       "      <td>[up, left]</td>\n",
       "      <td>[up, left]</td>\n",
       "      <td>[up, left]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[up, right]</td>\n",
       "      <td>[up]</td>\n",
       "      <td>[up, left]</td>\n",
       "      <td>[up, left]</td>\n",
       "      <td>[up, left]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[up, right]</td>\n",
       "      <td>[up]</td>\n",
       "      <td>[up, left]</td>\n",
       "      <td>[up, left]</td>\n",
       "      <td>[up, left]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         col_0                    col_1       col_2                    col_3  \\\n",
       "0      [right]  [up, down, left, right]      [left]  [up, down, left, right]   \n",
       "1  [up, right]                     [up]  [up, left]                   [left]   \n",
       "2  [up, right]                     [up]  [up, left]               [up, left]   \n",
       "3  [up, right]                     [up]  [up, left]               [up, left]   \n",
       "4  [up, right]                     [up]  [up, left]               [up, left]   \n",
       "\n",
       "        col_4  \n",
       "0      [left]  \n",
       "1      [left]  \n",
       "2  [up, left]  \n",
       "3  [up, left]  \n",
       "4  [up, left]  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.dict_to_grid(solver.find_optimal_policy(optimal_val_fun))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl_study",
   "language": "python",
   "name": "rl_study"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

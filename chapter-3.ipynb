{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Sequence, Tuple, Dict\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few examples of State Value function in the gridworld settings explained in [Chapter 3](http://incompleteideas.net/book/RLbook2018.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gridworld"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Gridworld environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridWorldEnv:\n",
    "    \"\"\"Manage Gridworld environment\"\"\"\n",
    "    def __init__(self, special_rewards: Dict, special_moves: Dict, dim: int = 5, ):\n",
    "        \"\"\"\n",
    "        Create gridworld\n",
    "        :param special_rewards: special reward when moving from this place, dict((row, col), reward)\n",
    "        :param special_rewards: special moves when moving from this place, dict((row, col), (dest_row, dest_col))\n",
    "        :param dim: grid lateral dimension\n",
    "        \"\"\"\n",
    "        assert len(special_moves) == len(special_rewards)\n",
    "        assert all(x in special_rewards for x in special_moves)\n",
    "        \n",
    "        self.special_reward = special_rewards\n",
    "        self.special_moves = special_moves\n",
    "        self.dim = dim\n",
    "        self.possible_actions = {\n",
    "            'up': (0, -1),\n",
    "            'down': (0, 1),\n",
    "            'left': (-1, 0),\n",
    "            'right': (1, 0)\n",
    "        }\n",
    "        \n",
    "    def show_full_space(self):\n",
    "        \"\"\"Show all possible action/state combinations and their rewards\"\"\"\n",
    "        for i in range(self.dim):\n",
    "            for k in range(self.dim):\n",
    "                for action_name, action in self.possible_actions.items():\n",
    "                    reward, next_pos = self.step(current_position=(i, k), action_name=action_name)\n",
    "                    print(f\"from {(i, k)} move {action_name} --> into {next_pos} with R={reward}\")\n",
    "                    \n",
    "    def step(self, current_position: Tuple[int, int], action_name: str):\n",
    "        \"\"\"Get reward and next position/state\"\"\"\n",
    "        assert action_name in self.possible_actions, f\"Action {action_name} not among possible actions\"\n",
    "        \n",
    "        action_x, action_y = self.possible_actions[action_name]\n",
    "        i, k = current_position\n",
    "        next_pos = i+action_x, k+action_y\n",
    "        if (i, k) in self.special_moves:  # special move get fixed reward and always move to one location\n",
    "            next_pos = self.special_moves[(i, k)]\n",
    "            reward = self.special_reward[(i, k)]\n",
    "        elif next_pos[0] < 0 or next_pos[0] > self.dim-1 or next_pos[1] < 0 or next_pos[1] > self.dim-1:\n",
    "            next_pos = i, k\n",
    "            reward = -1\n",
    "        else:\n",
    "            reward = 0\n",
    "        \n",
    "        return reward, next_pos\n",
    "    \n",
    "    def grid_to_vec(self, row: int, col: int) -> int:\n",
    "        \"\"\"get index of vector which corresponds to a grid position\"\"\"\n",
    "        assert 0 <= row < self.dim, f\"Invalid row number {row}, max is {self.dim - 1}\"\n",
    "        assert 0 <= col < self.dim, f\"Invalid column number {col}, max is {self.dim - 1}\"\n",
    "        \n",
    "        return row * self.dim + col\n",
    "\n",
    "    def vec_to_grid(self, idx: int) -> Tuple[int, int]:\n",
    "        \"\"\"get grid position which corresponds to index of vector\"\"\"\n",
    "        assert 0 <= idx < self.dim * self.dim, f\"Invalid index {idx}, max is {self.dim * self.dim - 1}\"\n",
    "        \n",
    "        return idx // self.dim, idx % self.dim\n",
    "    \n",
    "    def dict_to_grid(self, fun_on_grid: dict):\n",
    "        ans = []\n",
    "        for row in range(self.dim):\n",
    "            ans.append({f\"col_{col}\": fun_on_grid[(row, col)] for col in range(self.dim)})\n",
    "\n",
    "        return pd.DataFrame(ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use GridWorld with a small grid and display full spectrum of states-actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from (0, 0) move up --> into (0, 0) with R=-1\n",
      "from (0, 0) move down --> into (0, 1) with R=0\n",
      "from (0, 0) move left --> into (0, 0) with R=-1\n",
      "from (0, 0) move right --> into (1, 0) with R=0\n",
      "from (0, 1) move up --> into (0, 0) with R=0\n",
      "from (0, 1) move down --> into (0, 1) with R=-1\n",
      "from (0, 1) move left --> into (0, 1) with R=-1\n",
      "from (0, 1) move right --> into (1, 1) with R=0\n",
      "from (1, 0) move up --> into (1, 0) with R=-1\n",
      "from (1, 0) move down --> into (1, 1) with R=0\n",
      "from (1, 0) move left --> into (0, 0) with R=0\n",
      "from (1, 0) move right --> into (1, 0) with R=-1\n",
      "from (1, 1) move up --> into (0, 0) with R=10\n",
      "from (1, 1) move down --> into (0, 0) with R=10\n",
      "from (1, 1) move left --> into (0, 0) with R=10\n",
      "from (1, 1) move right --> into (0, 0) with R=10\n"
     ]
    }
   ],
   "source": [
    "env = GridWorldEnv(special_rewards={(1, 1): 10}, special_moves={(1, 1): (0, 0)}, dim=2)\n",
    "env.show_full_space()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a given policy (e.g. random policy) the Belmlman equation leads to the value function by solving a system of linear equations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bellman_eq_random_policy(env: GridWorldEnv, gamma: float):\n",
    "    \"\"\"\n",
    "    Solve bellman uquation under random policy\n",
    "    :param env: gridworl environment\n",
    "    :param: gamma: discount factor\n",
    "    \"\"\"\n",
    "    size = env.dim * env.dim  # linear system size\n",
    "    coeff = 1/4  # probability under random policy\n",
    "    matrix = np.zeros([size, size])\n",
    "    known_term = np.zeros(size)\n",
    "    \n",
    "    # build matrix\n",
    "    for idx in range(size):  # loop on equations\n",
    "        current_position = env.vec_to_grid(idx)\n",
    "        matrix[idx, idx] = 1\n",
    "        \n",
    "        for action in env.possible_actions:  # loop on four possible actions\n",
    "            reward, next_position = env.step(current_position=current_position, action_name=action)\n",
    "            known_term[idx] += coeff * reward\n",
    "            idx_other = env.grid_to_vec(*next_position)\n",
    "            matrix[idx, idx_other] -= coeff * gamma\n",
    "            \n",
    "    # solve linear system and push results to grid\n",
    "    res = np.linalg.solve(matrix, known_term)\n",
    "    \n",
    "    return env.dict_to_grid(fun_on_grid={env.vec_to_grid(x): np.around(res[x], 1) for x in range(size)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below gives teh value function for each state, under optimal policy.\n",
    "Result should be teh same as in [figure 3.2](http://incompleteideas.net/book/RLbook2018.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col_0</th>\n",
       "      <th>col_1</th>\n",
       "      <th>col_2</th>\n",
       "      <th>col_3</th>\n",
       "      <th>col_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.3</td>\n",
       "      <td>8.8</td>\n",
       "      <td>4.4</td>\n",
       "      <td>5.3</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>-1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.9</td>\n",
       "      <td>-1.3</td>\n",
       "      <td>-1.2</td>\n",
       "      <td>-1.4</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   col_0  col_1  col_2  col_3  col_4\n",
       "0    3.3    8.8    4.4    5.3    1.5\n",
       "1    1.5    3.0    2.3    1.9    0.5\n",
       "2    0.1    0.7    0.7    0.4   -0.4\n",
       "3   -1.0   -0.4   -0.4   -0.6   -1.2\n",
       "4   -1.9   -1.3   -1.2   -1.4   -2.0"
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = GridWorldEnv(special_rewards={(0, 1): 10, (0, 3): 5}, special_moves={(0, 1): (4, 1), (0, 3): (2, 3)})\n",
    "res = bellman_eq_random_policy(env=env, gamma=0.9)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl-study",
   "language": "python",
   "name": "rl-study"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
